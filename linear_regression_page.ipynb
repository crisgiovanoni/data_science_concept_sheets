{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Category                        \t| Method                                                         \t| Description                                                                                                                                                                                                                                            \t| Input                                                                                                                                                    \t| Return                                                                                                                                           \t|\n",
    "|---------------------------------\t|----------------------------------------------------------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\t|----------------------------------------------------------------------------------------------------------------------------------------------------------\t|--------------------------------------------------------------------------------------------------------------------------------------------------\t|\n",
    "| Filter Methods                   | **Correlation Thresholds**                                         \t| -Use correlation matrix and decide what new features to create                                                                                                                                                                                         \t| 1. data frame <br> 2. .corr() (pandas) <br>3. sns.heatmap                                                                                                         \t| 1. Heatmap with annotated R                                                                                                                      \t|\n",
    "|                                 \t| **SelectKBest**                                                    \t| -Removes all but highest scoring features <br>-Looks for: <br>a. Score as test statistic <br>b. P-value <br>-F-regression or Chi-square <br>-T-tests tells if a single variable is statistically significant; F-test tells if a group of variables are jointly significant \t| 1. SelectKBest method <br> 2. f_regression method (sklearn.feature_selection)                                                                                 \t| 1. Selected features that are significant                                                                                                        \t|\n",
    "| Wrapper Methods                 \t| **Backward Elimination**                                           \t| -Model is built already <br>-Checks performance of model then iteratively remove the worst performing features one by one until performance is \"acceptable\" <br>-Performance metric is p-value. p-value > 0.05, remove feature                                 \t| 1. LRmodel (sm.OLS) <br>2. X and y <br>3. Conditional (while loop or,boolean mask) that generates p-value and checks for and removes feature with p-value > 0.05 \t| 1. Resulting feature/s from condition (usually, column name)                                                                                     \t|\n",
    "|                                 \t| **Recursive Feature Elimination (RFE)**                            \t| -Recursively removes attributes then builds model on the remaining attributes <br>-Yields accuracy metric to rank feature according to importance                                                                                                          \t| 1. LReg model <br>2. RFE method <br>3. X and y                                                                                                                   \t| 1. rfe.ranking_ (ranking of variables based on importance level, 1=important) <br>2. rfe.support_(support of variables (True/False, keep or discard) \t|\n",
    "|                                 \t| **Forward Selection**                                              \t|                                                                                                                                                                                                                                                        \t|                                                                                                                                                          \t|                                                                                                                                                  \t|\n",
    "| Embedded Methods                \t| **LassoCV**                                                        \t| -Penalizes irrelevant features by making its coefficient=0. <br>-Weights the coefficient by virtue of relevance <br>-High α ≈ More non-zero value features                                                                                                     \t| 1. LReg model <br>2. LassoCV method (sklearn.linear_model)                                                                                                   \t| 1. alpha_ <br>2. coef_                                                                                                                               \t|\n",
    "|                                 \t| **Others: -Elastic Net <br>-Ridge Regression <br>-Regularized Regression**        \t|                                                                                                                                                                                                                                                        \t|                                                                                                                                                          \t|                                                                                                                                                  \t|\n",
    "| Linear Dimensionality Reduction \t| **Principal Component Analysis (PCA)**                             \t| -Creates a new feature, aka Principal Component which combines X1 and X2 <br>-Ranked in order of explained variance <br>-Only takes in normalized dataset <br>-New Principal Components are not interpretable                                                      \t| 1. PCA method (sklearn.decomposition)                                                                                                                    \t| 1. n_components_ <br>2. pca_explained_variance_ratio_                                                                                                \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
